# Бібліотека MPI

[Перелік лекцій](README.md)

## Узагальнено

MPI (Message Passing Interface) - це стандарт, призначений для передачі повідомлень між процесами, які працюють на різних вузлах кластера або мережі комп'ютерів. MPI використовується для розподілених обчислень в багатопроцесорних та багатоузлових середовищах, де кожен процесор виконує окрему частину обчислень.

MPI можна використовувати для розподіленого виконання коду на декількох вузлах, також для обміну даними та координації дій між процесами. Це дає змогу збільшити продуктивність обчислень, зменшити час виконання та підвищити масштабованість програм.

MPI складається з функцій бібліотеки, які можна використовувати у програмі для передачі повідомлень, отримання даних від інших процесів та координації дій. MPI також містить структури даних та інші корисні інструменти для роботи з розподіленими системами.

MPI може бути використаний в різних мовах програмування, включаючи C, C++, Fortran та Python. Щоб використовувати MPI, потрібно встановити бібліотеку MPI та скомпілювати програму з використанням MPI.

Одним з головних переваг MPI є його масштабованість. Він може бути використаний для розподілених систем будь-якої розмірності та з будь-якою кількістю процесів. MPI також надає високу продуктивність та ефективність роботи в розподілених системах.

Одним з основних недоліків MPI є складність програмування та підтримки. Розробка програм з використанням MPI може бути складною та часом підвищувати складність програмного коду. 

### Переваги MPI:


- MPI є стандартом та підтримується різними виробниками обладнання та програмного забезпечення.
- MPI може використовуватись на багатьох різних архітектурах, таких як кластери, мультипроцесорні системи, грід-обчислення, і т.д.
- MPI дозволяє ефективно використовувати ресурси, що знаходяться на різних вузлах мережі.
- MPI може бути використаний для взаємодії між процесами на одній машині, а також для взаємодії між процесами на різних машинах.
- MPI дозволяє розробляти додатки, які можуть працювати на різних операційних системах, таких як Linux, Windows, Mac OS і т.д.
- Підтримка багатьох мов програмування: MPI можна використовувати з більшістю мов програмування, таких як С++, Фортран, Python і Java.
- Гнучкість: MPI дозволяє розподіляти обчислювальні ресурси між вузлами кластера, що дозволяє ефективно використовувати доступні обчислювальні ресурси.
- Висока продуктивність: MPI дозволяє ефективно використовувати паралельні алгоритми, що дозволяє зменшити час виконання складних обчислювальних завдань.
- Розширюваність: MPI можна використовувати для паралельного програмування відносно невеликих кластерів до великих суперкомп'ютерів.
- Підтримка різних топологій: MPI дозволяє використовувати різні топології для організації комунікації між вузлами кластера.
- Надійність: MPI має вбудовану підтримку обробки помилок і механізми забезпечення надійної передачі повідомлень.

### Недоліки MPI

- MPI потребує додаткового програмування з боку розробника для взаємодії між процесами.
- MPI може бути складним у використанні, зокрема, якщо необхідно обмінюватись складними даними між процесами.
- MPI не забезпечує автоматичної маршрутизації повідомлень, тому розробник повинен самостійно забезпечувати правильну передачу повідомлень між процесами.
- MPI не підтримує автоматичну оптимізацію взаємодії між процесами та потребує від розробника вручну оптимізувати комунікацію між процесами.
- Складність програмування: MPI може бути складним для розуміння та використання, особливо для початківців. Необхідно знати досить багато процедур та функцій, а також детально розуміти процеси та комунікацію між ними.
- Складність налагодження: відлагодження паралельної програми може бути складним завданням, особливо, якщо ви маєте справу з великою кількістю процесів.
- Залежність від архітектури: MPI розроблено з урахуванням розподіленого середовища та паралельних архітектур. Це означає, що використання MPI на вузькопрофільних системах може бути недоцільним.
- Проблеми зі сумісністю: різні версії MPI можуть мати різні функціональність та сумісність з різними платформами. Це може призвести до проблем з сумісністю, які можуть бути важкими для вирішення.

## Порівняння MPI та OpenMP

MPI та OpenMP є двома різними бібліотеками для паралельного програмування на багатоядерних та розподілених системах. Обидві бібліотеки мають свої переваги та недоліки та можуть бути використані для різних цілей.

MPI - це бібліотека для програмування розподілених систем, де кожен процес може працювати на різних комп'ютерах. MPI дозволяє розподіляти завдання між різними процесами та забезпечує можливість взаємодії між процесами. Основною перевагою MPI є масштабовність, яка дозволяє використовувати багато комп'ютерів для розподілених обчислень.

OpenMP - це бібліотека для паралельного програмування на багатоядерних системах, де всі процеси працюють на одному комп'ютері. OpenMP дозволяє розподіляти завдання між різними ядрами процесора та забезпечує можливість взаємодії між ними. Основною перевагою OpenMP є простота використання та можливість використовувати багато ядер для паралельних обчислень.

Однак, MPI та OpenMP не є взаємозамінними, і використовуються для різних завдань. MPI зазвичай використовується для розподілених обчислень, де кожен процес працює на різному комп'ютері, а OpenMP використовується для паралельних обчислень на багатоядерних системах. Крім того, MPI має додаткові функції для забезпечення комунікації між процесами та синхронізації, яких немає в OpenMP.

## Приклад

```cpp
#include <iostream>
#include <mpi.h>
#define ARRAY_SIZE 1000000

int main(int argc, char ** argv) {
  int my_rank, num_procs, num_elements_per_proc, i;
  int array[ARRAY_SIZE];
  int sum = 0, partial_sum = 0;
  // Ініціалізація MPI
  MPI_Init( & argc, & argv);
  MPI_Comm_size(MPI_COMM_WORLD, & num_procs);
  MPI_Comm_rank(MPI_COMM_WORLD, & my_rank);

  // Обчислення кількості елементів на процес
  num_elements_per_proc = ARRAY_SIZE / num_procs;

  // Генерація масиву на кореневому процесі
  if (my_rank == 0) {
    for (i = 0; i < ARRAY_SIZE; i++) {
      array[i] = i;
    }
  }
  // Розсилка масиву на всі процеси
  MPI_Scatter(array, num_elements_per_proc, MPI_INT, array, num_elements_per_proc, MPI_INT, 0, MPI_COMM_WORLD);
  // Обчислення часткової суми для кожного процесу
  for (i = 0; i < num_elements_per_proc; i++) {
    partial_sum += array[i];
  }
  // Збір часткових сум з усіх процесів на кореневий процес
  MPI_Reduce( & partial_sum, & sum, 1, MPI_INT, MPI_SUM, 0, MPI_COMM_WORLD);
  // Виведення кінцевого результату на кореневому процесі
  if (my_rank == 0) {
    std::cout << "Сума елементів масиву = " << sum << std::endl;
  }
  // Завершення роботи MPI
  MPI_Finalize();

  return 0;
}
```

У цій програмі кожен процес отримує підмасив масиву array, обчислює його часткову суму та повертає її на кореневий процес. Кореневий процес збирає всі часткові суми та обчислює загальну суму елементів масиву.

Програма використовує декілька функцій MPI, таких як MPI_Init, MPI_Comm_size, MPI_Comm_rank, MPI_Scatter, MPI_Reduce та MPI_Finalize. Функція MPI_Init ініціалізує бібліотеку MPI, MPI_Comm_size та MPI_Comm_rank визначають загальну кількість процесів та номер поточного процесу в комунікаторі. Функція MPI_Scatter розподіляє масив на рівні частини серед усіх процесів, MPI_Reduce збирає часткові суми з усіх процесів та обчислює загальну суму, а MPI_Finalize завершує роботу бібліотеки MPI.

## Контрольні питання

1. Що таке MPI і як вона використовується в програмуванні?
2. Які існують типи комунікації в MPI?
3. Які функції відповідають за надсилання повідомлень в MPI?
4. Як можна визначити ранг процесу у MPI?
5. Які можливості надає MPI для розподіленого обчислення?
6. Які проблеми можуть виникнути при використанні MPI на кластерах?
7. Як можна визначити кількість процесорів на кластері за допомогою MPI?
8. Які є особливості створення та запуску MPI-додатків?
9. Які є підходи до розподіленої обробки даних в MPI?
10. Як визначити оптимальну кількість процесів для запуску MPI-додатків на кластері?